"""
ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
"""

import pandas as pd
import numpy as np
from typing import Dict, List


def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì»¬ëŸ¼ëª…ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ì»¬ëŸ¼ëª…ì´ ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    df_clean = df.copy()
    
    # CSV ì‹¤ì œ ì»¬ëŸ¼ êµ¬ì¡°:
    # 0: ìš”ì¼êµ¬ë¶„ (í‰ì¼, í† ìš”ì¼, ì¼ìš”ì¼)
    # 1: í˜¸ì„ 
    # 2: ì—­ë²ˆí˜¸
    # 3: ì¶œë°œì—­ (ì—­ëª…)
    # 4: ìƒí•˜êµ¬ë¶„ (í‰ì¼, íœ´ì¼, ë‚´ì„ , ì™¸ì„ ) -> ë°©í–¥ ì •ë³´
    
    cols = list(df_clean.columns)
    
    # ì²« 5ê°œ ì»¬ëŸ¼ ì´ë¦„ í‘œì¤€í™”
    new_cols = ['ìš”ì¼êµ¬ë¶„', 'í˜¸ì„ ', 'ì—­ë²ˆí˜¸', 'ì—­ëª…', 'ë°©í–¥'] + cols[5:]
    df_clean.columns = new_cols
    
    return df_clean


def convert_time_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì‹œê°„ëŒ€ ì»¬ëŸ¼ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ì‹œê°„ëŒ€ ì»¬ëŸ¼ì´ ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
    """
    df_clean = df.copy()
    
    # ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë§¤í•‘ (ì›ë³¸ -> í‘œì¤€ í˜•ì‹)
    time_mapping = {}
    
    # ì‹œê°„ëŒ€ íŒ¨í„´: "5ì‹œ30ë¶„", "6ì‹œ00ë¶„" ë“±
    for col in df.columns:
        if 'ì‹œ' in col and 'ë¶„' in col:
            # "5ì‹œ30ë¶„" -> "05:30"
            col_clean = col.replace('ì‹œ', ':').replace('ë¶„', '').strip()
            
            # ì‹œê°„ íŒŒì‹±
            parts = col_clean.split(':')
            if len(parts) == 2:
                hour = int(parts[0])
                minute = int(parts[1])
                
                # 0ì‹œëŠ” 24:00ìœ¼ë¡œ í‘œì‹œ
                if hour == 0:
                    hour = 24
                
                time_str = f"{hour:02d}:{minute:02d}"
                time_mapping[col] = time_str
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    df_clean.rename(columns=time_mapping, inplace=True)
    
    return df_clean


def clean_congestion_values(df: pd.DataFrame, time_columns: List[str]) -> pd.DataFrame:
    """
    í˜¼ì¡ë„ ê°’ì„ ì •ë¦¬í•©ë‹ˆë‹¤ (ë¬¸ìì—´ -> float ë³€í™˜, ê³µë°± ì œê±°).
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        time_columns: ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        pd.DataFrame: í˜¼ì¡ë„ ê°’ì´ ì •ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    df_clean = df.copy()
    
    for col in time_columns:
        if col in df_clean.columns:
            # ë¬¸ìì—´ ê³µë°± ì œê±° í›„ float ë³€í™˜
            df_clean[col] = pd.to_numeric(df_clean[col].astype(str).str.strip(), errors='coerce')
            
            # ìŒìˆ˜ ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
            df_clean[col] = df_clean[col].clip(lower=0)
            
            # ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
            df_clean[col] = df_clean[col].fillna(0)
    
    return df_clean


def melt_to_long_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    Wide formatì„ Long formatìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: Wide format ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: Long format ë°ì´í„°í”„ë ˆì„
    """
    # ì‹œê°„ëŒ€ ì»¬ëŸ¼ ì¶”ì¶œ (HH:MM í˜•ì‹)
    time_columns = [col for col in df.columns if ':' in str(col)]
    
    # ê¸°ë³¸ ì»¬ëŸ¼ (ì‹œê°„ëŒ€ê°€ ì•„ë‹Œ ì»¬ëŸ¼)
    id_columns = [col for col in df.columns if col not in time_columns]
    
    # Melt ìˆ˜í–‰
    df_long = pd.melt(
        df,
        id_vars=id_columns,
        value_vars=time_columns,
        var_name='ì‹œê°„ëŒ€',
        value_name='í˜¼ì¡ë„'
    )
    
    # ì‹œê°„ëŒ€ë¥¼ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•œ ì‹œê°„ ê°’ ìƒì„±
    df_long['ì‹œê°„_ì •ë ¬ìš©'] = df_long['ì‹œê°„ëŒ€'].apply(lambda x: 
        int(x.split(':')[0]) * 60 + int(x.split(':')[1])
    )
    
    # ì •ë ¬
    df_long = df_long.sort_values(['í˜¸ì„ ', 'ì—­ëª…', 'ë°©í–¥', 'ìš”ì¼êµ¬ë¶„', 'ì‹œê°„_ì •ë ¬ìš©'])
    
    # ì¸ë±ìŠ¤ ë¦¬ì…‹
    df_long = df_long.reset_index(drop=True)
    
    return df_long


def add_derived_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    íŒŒìƒ ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: íŒŒìƒ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    df_derived = df.copy()
    
    # í˜¼ì¡ë„ ë ˆë²¨ (ì—¬ìœ /ë³´í†µ/í˜¼ì¡)
    def get_congestion_level(congestion: float) -> str:
        if congestion < 50:
            return 'ì—¬ìœ '
        elif congestion < 70:
            return 'ë³´í†µ'
        else:
            return 'í˜¼ì¡'
    
    df_derived['í˜¼ì¡ë„_ë ˆë²¨'] = df_derived['í˜¼ì¡ë„'].apply(get_congestion_level)
    
    # ì‹œê°„ëŒ€ êµ¬ë¶„ (ìƒˆë²½/ì˜¤ì „/ì˜¤í›„/ì €ë…/ì‹¬ì•¼)
    def get_time_period(time_str: str) -> str:
        hour = int(time_str.split(':')[0])
        if 5 <= hour < 9:
            return 'ì¶œê·¼ì‹œê°„'
        elif 9 <= hour < 12:
            return 'ì˜¤ì „'
        elif 12 <= hour < 14:
            return 'ì ì‹¬ì‹œê°„'
        elif 14 <= hour < 18:
            return 'ì˜¤í›„'
        elif 18 <= hour < 21:
            return 'í‡´ê·¼ì‹œê°„'
        elif 21 <= hour < 24:
            return 'ì €ë…'
        else:
            return 'ì‹¬ì•¼'
    
    df_derived['ì‹œê°„ëŒ€_êµ¬ë¶„'] = df_derived['ì‹œê°„ëŒ€'].apply(get_time_period)
    
    # í˜¸ì„  ë²ˆí˜¸ (ì •ë ¬ìš©)
    df_derived['í˜¸ì„ _ë²ˆí˜¸'] = df_derived['í˜¸ì„ '].str.extract(r'(\d+)').astype(int)
    
    return df_derived


def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì „ì²´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„
    """
    print("\n[ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...]")
    print(f"   ì›ë³¸ ë°ì´í„°: {df.shape}")
    
    # 1. ì»¬ëŸ¼ëª… ì •ë¦¬
    print("\n[1] ì»¬ëŸ¼ëª… ì •ë¦¬ ì¤‘...")
    df = clean_column_names(df)
    
    # 2. ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë³€í™˜
    print("[2] ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë³€í™˜ ì¤‘...")
    df = convert_time_columns(df)
    
    # 3. ì‹œê°„ëŒ€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    time_columns = [col for col in df.columns if ':' in str(col)]
    print(f"   ì‹œê°„ëŒ€ ì»¬ëŸ¼ ìˆ˜: {len(time_columns)}")
    
    # 4. í˜¼ì¡ë„ ê°’ ì •ë¦¬
    print("[3] í˜¼ì¡ë„ ê°’ ì •ë¦¬ ì¤‘...")
    df = clean_congestion_values(df, time_columns)
    
    # 5. Long formatìœ¼ë¡œ ë³€í™˜
    print("[4] Long formatìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    df_long = melt_to_long_format(df)
    print(f"   ë³€í™˜ í›„ ë°ì´í„°: {df_long.shape}")
    
    # 6. íŒŒìƒ ì»¬ëŸ¼ ì¶”ê°€
    print("[5] íŒŒìƒ ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
    df_final = add_derived_columns(df_long)
    
    print(f"\n[ì™„ë£Œ] ì „ì²˜ë¦¬ ì™„ë£Œ: {df_final.shape}")
    print(f"   ì»¬ëŸ¼: {list(df_final.columns)}")
    
    return df_final


def get_statistics(df: pd.DataFrame) -> Dict:
    """
    ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        dict: í†µê³„ ì •ë³´
    """
    stats = {
        'ì´_ë°ì´í„°_ìˆ˜': len(df),
        'í˜¸ì„ _ìˆ˜': df['í˜¸ì„ '].nunique(),
        'ì—­_ìˆ˜': df['ì—­ëª…'].nunique(),
        'í‰ê· _í˜¼ì¡ë„': df['í˜¼ì¡ë„'].mean(),
        'ìµœëŒ€_í˜¼ì¡ë„': df['í˜¼ì¡ë„'].max(),
        'ìµœì†Œ_í˜¼ì¡ë„': df['í˜¼ì¡ë„'].min(),
        'í˜¼ì¡ë„_í‘œì¤€í¸ì°¨': df['í˜¼ì¡ë„'].std(),
    }
    
    # ê°€ì¥ í˜¼ì¡í•œ ì—­/ì‹œê°„ëŒ€
    if len(df) > 0:
        max_idx = df['í˜¼ì¡ë„'].idxmax()
        stats['ê°€ì¥_í˜¼ì¡í•œ_ì—­'] = df.loc[max_idx, 'ì—­ëª…']
        stats['ê°€ì¥_í˜¼ì¡í•œ_ì‹œê°„'] = df.loc[max_idx, 'ì‹œê°„ëŒ€']
        stats['ê°€ì¥_í˜¼ì¡í•œ_í˜¼ì¡ë„'] = df.loc[max_idx, 'í˜¼ì¡ë„']
    
    return stats


def validate_data(df: pd.DataFrame) -> bool:
    """
    ë°ì´í„° ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
    """
    print("\n[ë°ì´í„° ìœ íš¨ì„± ê²€ì¦...]")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['í˜¸ì„ ', 'ì—­ëª…', 'ë°©í–¥', 'ìš”ì¼êµ¬ë¶„', 'ì‹œê°„ëŒ€', 'í˜¼ì¡ë„']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"[ì˜¤ë¥˜] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        return False
    
    print("[ì™„ë£Œ] í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ")
    
    # ë°ì´í„° íƒ€ì… í™•ì¸
    if not pd.api.types.is_numeric_dtype(df['í˜¼ì¡ë„']):
        print("[ì˜¤ë¥˜] í˜¼ì¡ë„ ì»¬ëŸ¼ì´ ìˆ«ìí˜•ì´ ì•„ë‹™ë‹ˆë‹¤")
        return False
    
    print("[ì™„ë£Œ] ë°ì´í„° íƒ€ì… í™•ì¸ ì™„ë£Œ")
    
    # í˜¼ì¡ë„ ë²”ìœ„ í™•ì¸
    if df['í˜¼ì¡ë„'].min() < 0:
        print("[ê²½ê³ ] ìŒìˆ˜ í˜¼ì¡ë„ ê°’ì´ ìˆìŠµë‹ˆë‹¤")
    
    if df['í˜¼ì¡ë„'].max() > 200:
        print("[ê²½ê³ ] ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ í˜¼ì¡ë„ ê°’ì´ ìˆìŠµë‹ˆë‹¤ (200% ì´ìƒ)")
    
    print("[ì™„ë£Œ] í˜¼ì¡ë„ ë²”ìœ„ í™•ì¸ ì™„ë£Œ")
    
    # ê²°ì¸¡ì¹˜ í™•ì¸
    null_counts = df[required_columns].isnull().sum()
    if null_counts.sum() > 0:
        print(f"[ê²½ê³ ] ê²°ì¸¡ì¹˜ ë°œê²¬:\n{null_counts[null_counts > 0]}")
    else:
        print("[ì™„ë£Œ] ê²°ì¸¡ì¹˜ ì—†ìŒ")
    
    return True


# ============================================================
# Phase 2: ì§‘ê³„ ë° í•„í„° í•¨ìˆ˜
# ============================================================

def filter_data(
    df: pd.DataFrame,
    day_type: str = "ì „ì²´",
    lines: List[str] = None,
    time_range: tuple = None
) -> pd.DataFrame:
    """
    í•„í„° ì¡°ê±´ì— ë”°ë¼ ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        day_type: ìš”ì¼ êµ¬ë¶„ ("í‰ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼", "íœ´ì¼", "ì „ì²´")
        lines: ì„ íƒëœ í˜¸ì„  ë¦¬ìŠ¤íŠ¸
        time_range: ì‹œê°„ ë²”ìœ„ (ì‹œì‘ì‹œ, ì¢…ë£Œì‹œ) íŠœí”Œ
        
    Returns:
        pd.DataFrame: í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
    """
    df_filtered = df.copy()
    
    # ìš”ì¼ í•„í„°
    if day_type and day_type != "ì „ì²´":
        if day_type == "íœ´ì¼":
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'].isin(['í† ìš”ì¼', 'ì¼ìš”ì¼'])]
        else:
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'] == day_type]
    
    # í˜¸ì„  í•„í„°
    if lines and len(lines) > 0:
        df_filtered = df_filtered[df_filtered['í˜¸ì„ '].isin(lines)]
    
    # ì‹œê°„ ë²”ìœ„ í•„í„°
    if time_range:
        start_hour, end_hour = time_range
        df_filtered = df_filtered[
            (df_filtered['ì‹œê°„_ì •ë ¬ìš©'] >= start_hour * 60) & 
            (df_filtered['ì‹œê°„_ì •ë ¬ìš©'] <= end_hour * 60)
        ]
    
    return df_filtered


def get_congestion_by_line(df: pd.DataFrame) -> pd.DataFrame:
    """
    í˜¸ì„ ë³„ í‰ê·  í˜¼ì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: í˜¸ì„ ë³„ í‰ê·  í˜¼ì¡ë„
    """
    result = df.groupby('í˜¸ì„ ').agg({
        'í˜¼ì¡ë„': 'mean',
        'ì—­ëª…': 'nunique'
    }).reset_index()
    
    result.columns = ['í˜¸ì„ ', 'í‰ê· _í˜¼ì¡ë„', 'ì—­_ìˆ˜']
    
    # í˜¸ì„  ë²ˆí˜¸ë¡œ ì •ë ¬
    result['í˜¸ì„ _ë²ˆí˜¸'] = result['í˜¸ì„ '].str.extract(r'(\d+)').astype(int)
    result = result.sort_values('í˜¸ì„ _ë²ˆí˜¸').drop(columns=['í˜¸ì„ _ë²ˆí˜¸'])
    
    return result.reset_index(drop=True)


def get_congestion_by_time(df: pd.DataFrame, group_by: str = None) -> pd.DataFrame:
    """
    ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        group_by: ì¶”ê°€ ê·¸ë£¹ ì»¬ëŸ¼ (ì˜ˆ: 'ìš”ì¼êµ¬ë¶„', 'í˜¸ì„ ')
        
    Returns:
        pd.DataFrame: ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„
    """
    if group_by:
        result = df.groupby(['ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©', group_by])['í˜¼ì¡ë„'].mean().reset_index()
    else:
        result = df.groupby(['ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    
    result = result.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    
    return result


def get_top_stations(
    df: pd.DataFrame,
    n: int = 10,
    ascending: bool = False
) -> pd.DataFrame:
    """
    í˜¼ì¡ë„ ê¸°ì¤€ TOP N ì—­ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        n: ë°˜í™˜í•  ì—­ ê°œìˆ˜
        ascending: Trueë©´ ì—¬ìœ ë¡œìš´ ì—­, Falseë©´ í˜¼ì¡í•œ ì—­
        
    Returns:
        pd.DataFrame: TOP N ì—­ ë°ì´í„°í”„ë ˆì„
    """
    # ì—­ë³„ í‰ê·  í˜¼ì¡ë„ ê³„ì‚°
    result = df.groupby(['í˜¸ì„ ', 'ì—­ëª…']).agg({
        'í˜¼ì¡ë„': ['mean', 'max']
    }).reset_index()
    
    result.columns = ['í˜¸ì„ ', 'ì—­ëª…', 'í‰ê· _í˜¼ì¡ë„', 'ìµœëŒ€_í˜¼ì¡ë„']
    
    # ì •ë ¬ ë° TOP N ì¶”ì¶œ
    result = result.sort_values('í‰ê· _í˜¼ì¡ë„', ascending=ascending).head(n)
    
    # ìˆœìœ„ ì¶”ê°€
    result = result.reset_index(drop=True)
    result.insert(0, 'ìˆœìœ„', range(1, len(result) + 1))
    
    return result


def get_congestion_by_day_time(df: pd.DataFrame) -> pd.DataFrame:
    """
    ìš”ì¼êµ¬ë¶„ + ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    (í‰ì¼ vs íœ´ì¼ ë¹„êµ ì°¨íŠ¸ìš©)
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ìš”ì¼êµ¬ë¶„/ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„
    """
    result = df.groupby(['ìš”ì¼êµ¬ë¶„', 'ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    result = result.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    
    return result


def get_peak_info(df: pd.DataFrame) -> Dict:
    """
    í”¼í¬ ì‹œê°„ëŒ€ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        dict: í”¼í¬ ì •ë³´ (ì‹œê°„ëŒ€, í˜¼ì¡ë„ ë“±)
    """
    # ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„
    time_avg = df.groupby('ì‹œê°„ëŒ€')['í˜¼ì¡ë„'].mean()
    
    # í”¼í¬ ì‹œê°„ëŒ€
    peak_time = time_avg.idxmax()
    peak_congestion = time_avg.max()
    
    # ê°€ì¥ ì—¬ìœ ë¡œìš´ ì‹œê°„ëŒ€
    quiet_time = time_avg.idxmin()
    quiet_congestion = time_avg.min()
    
    return {
        'í”¼í¬_ì‹œê°„': peak_time,
        'í”¼í¬_í˜¼ì¡ë„': peak_congestion,
        'ì—¬ìœ _ì‹œê°„': quiet_time,
        'ì—¬ìœ _í˜¼ì¡ë„': quiet_congestion,
    }


def get_line_list(df: pd.DataFrame) -> List[str]:
    """
    í˜¸ì„  ëª©ë¡ì„ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        List[str]: ì •ë ¬ëœ í˜¸ì„  ëª©ë¡
    """
    lines = df['í˜¸ì„ '].unique().tolist()
    # ìˆ«ì ê¸°ì¤€ ì •ë ¬
    lines.sort(key=lambda x: int(x.replace('í˜¸ì„ ', '').strip()) if x.replace('í˜¸ì„ ', '').strip().isdigit() else 999)
    return lines


def get_time_slots(df: pd.DataFrame) -> List[str]:
    """
    ì‹œê°„ëŒ€ ëª©ë¡ì„ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        
    Returns:
        List[str]: ì •ë ¬ëœ ì‹œê°„ëŒ€ ëª©ë¡
    """
    time_df = df[['ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©']].drop_duplicates()
    time_df = time_df.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    return time_df['ì‹œê°„ëŒ€'].tolist()


# ============================================================
# Phase 3: ì—­ë³„ ë¶„ì„ í•¨ìˆ˜
# ============================================================

def get_station_list(df: pd.DataFrame, line: str = None) -> List[str]:
    """
    íŠ¹ì • í˜¸ì„ ì˜ ì—­ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        line: í˜¸ì„ ëª… (Noneì´ë©´ ì „ì²´ ì—­ ëª©ë¡)
        
    Returns:
        List[str]: ì •ë ¬ëœ ì—­ ëª©ë¡
    """
    if line:
        stations = df[df['í˜¸ì„ '] == line]['ì—­ëª…'].unique().tolist()
    else:
        stations = df['ì—­ëª…'].unique().tolist()
    
    stations.sort()
    return stations


def get_station_data(df: pd.DataFrame, station: str, line: str) -> pd.DataFrame:
    """
    íŠ¹ì • ì—­ì˜ ì „ì²´ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        
    Returns:
        pd.DataFrame: í•´ë‹¹ ì—­ì˜ ë°ì´í„°
    """
    return df[(df['ì—­ëª…'] == station) & (df['í˜¸ì„ '] == line)].copy()


def get_station_stats(df: pd.DataFrame, station: str, line: str) -> Dict:
    """
    ì—­ë³„ í†µê³„ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        
    Returns:
        Dict: ì—­ë³„ í†µê³„ ì •ë³´
    """
    station_df = get_station_data(df, station, line)
    
    if station_df.empty:
        return {
            'í‰ê· _í˜¼ì¡ë„': 0,
            'ìµœëŒ€_í˜¼ì¡ë„': 0,
            'ìµœì†Œ_í˜¼ì¡ë„': 0,
            'í”¼í¬_ì‹œê°„': '-',
            'í”¼í¬_í˜¼ì¡ë„': 0,
            'ì—¬ìœ _ì‹œê°„': '-',
            'ì—¬ìœ _í˜¼ì¡ë„': 0,
        }
    
    # ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„
    time_avg = station_df.groupby('ì‹œê°„ëŒ€')['í˜¼ì¡ë„'].mean()
    
    # í”¼í¬/ì—¬ìœ  ì‹œê°„ëŒ€
    peak_time = time_avg.idxmax()
    peak_congestion = time_avg.max()
    quiet_time = time_avg.idxmin()
    quiet_congestion = time_avg.min()
    
    return {
        'í‰ê· _í˜¼ì¡ë„': station_df['í˜¼ì¡ë„'].mean(),
        'ìµœëŒ€_í˜¼ì¡ë„': station_df['í˜¼ì¡ë„'].max(),
        'ìµœì†Œ_í˜¼ì¡ë„': station_df['í˜¼ì¡ë„'].min(),
        'í”¼í¬_ì‹œê°„': peak_time,
        'í”¼í¬_í˜¼ì¡ë„': peak_congestion,
        'ì—¬ìœ _ì‹œê°„': quiet_time,
        'ì—¬ìœ _í˜¼ì¡ë„': quiet_congestion,
    }


def get_station_direction_comparison(df: pd.DataFrame, station: str, line: str) -> pd.DataFrame:
    """
    ìƒí–‰/í•˜í–‰ ë°©í–¥ë³„ ì‹œê°„ëŒ€ í˜¼ì¡ë„ ë¹„êµ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        
    Returns:
        pd.DataFrame: ë°©í–¥ë³„ ì‹œê°„ëŒ€ í˜¼ì¡ë„ ë°ì´í„°
    """
    station_df = get_station_data(df, station, line)
    
    if station_df.empty:
        return pd.DataFrame()
    
    # ë°©í–¥ë³„ ì‹œê°„ëŒ€ í‰ê·  í˜¼ì¡ë„
    result = station_df.groupby(['ë°©í–¥', 'ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    result = result.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    
    return result


def get_station_day_comparison(df: pd.DataFrame, station: str, line: str) -> pd.DataFrame:
    """
    í‰ì¼/í† ìš”ì¼/ì¼ìš”ì¼ ìš”ì¼ë³„ í˜¼ì¡ë„ ë¹„êµ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        
    Returns:
        pd.DataFrame: ìš”ì¼ë³„ ì‹œê°„ëŒ€ í˜¼ì¡ë„ ë°ì´í„°
    """
    station_df = get_station_data(df, station, line)
    
    if station_df.empty:
        return pd.DataFrame()
    
    # ìš”ì¼ë³„ ì‹œê°„ëŒ€ í‰ê·  í˜¼ì¡ë„
    result = station_df.groupby(['ìš”ì¼êµ¬ë¶„', 'ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    result = result.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    
    return result


def get_station_heatmap_data(df: pd.DataFrame, station: str, line: str, 
                              pivot_by: str = 'ë°©í–¥') -> pd.DataFrame:
    """
    íˆíŠ¸ë§µìš© í”¼ë²— ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        pivot_by: í”¼ë²— ê¸°ì¤€ ('ë°©í–¥' ë˜ëŠ” 'ìš”ì¼êµ¬ë¶„')
        
    Returns:
        pd.DataFrame: í”¼ë²—ëœ íˆíŠ¸ë§µ ë°ì´í„°
    """
    station_df = get_station_data(df, station, line)
    
    if station_df.empty:
        return pd.DataFrame()
    
    # ê·¸ë£¹ë³„ í‰ê·  í˜¼ì¡ë„
    grouped = station_df.groupby([pivot_by, 'ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    
    # í”¼ë²— í…Œì´ë¸” ìƒì„±
    pivot = grouped.pivot_table(
        values='í˜¼ì¡ë„',
        index=pivot_by,
        columns='ì‹œê°„ëŒ€',
        aggfunc='mean'
    )
    
    # ì‹œê°„ëŒ€ ìˆœìœ¼ë¡œ ì»¬ëŸ¼ ì •ë ¬
    time_order = grouped.sort_values('ì‹œê°„_ì •ë ¬ìš©')['ì‹œê°„ëŒ€'].unique()
    pivot = pivot.reindex(columns=time_order)
    
    return pivot


def generate_station_insights(df: pd.DataFrame, station: str, line: str) -> List[str]:
    """
    ì—­ë³„ ìë™ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        station: ì—­ëª…
        line: í˜¸ì„ ëª…
        
    Returns:
        List[str]: ì¸ì‚¬ì´íŠ¸ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
    """
    insights = []
    station_df = get_station_data(df, station, line)
    
    if station_df.empty:
        return ["ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]
    
    stats = get_station_stats(df, station, line)
    
    # 1. í”¼í¬ ì‹œê°„ëŒ€ ì¸ì‚¬ì´íŠ¸
    insights.append(
        f"ğŸ• ì´ ì—­ì€ **{stats['í”¼í¬_ì‹œê°„']}**ì— ê°€ì¥ í˜¼ì¡í•©ë‹ˆë‹¤ (í˜¼ì¡ë„ {stats['í”¼í¬_í˜¼ì¡ë„']:.1f}%)"
    )
    
    # 2. ê°€ì¥ ì—¬ìœ ë¡œìš´ ì‹œê°„ëŒ€
    insights.append(
        f"ğŸ˜Š ê°€ì¥ ì—¬ìœ ë¡œìš´ ì‹œê°„ëŒ€ëŠ” **{stats['ì—¬ìœ _ì‹œê°„']}**ì…ë‹ˆë‹¤ (í˜¼ì¡ë„ {stats['ì—¬ìœ _í˜¼ì¡ë„']:.1f}%)"
    )
    
    # 3. í‰ì¼ vs íœ´ì¼ ë¹„êµ
    weekday_avg = station_df[station_df['ìš”ì¼êµ¬ë¶„'] == 'í‰ì¼']['í˜¼ì¡ë„'].mean()
    weekend_avg = station_df[station_df['ìš”ì¼êµ¬ë¶„'].isin(['í† ìš”ì¼', 'ì¼ìš”ì¼'])]['í˜¼ì¡ë„'].mean()
    
    if weekday_avg > 0 and weekend_avg > 0:
        diff = weekday_avg - weekend_avg
        if diff > 5:
            insights.append(
                f"ğŸ“… í‰ì¼ì´ ì£¼ë§ë³´ë‹¤ í‰ê·  **{diff:.1f}%** ë” í˜¼ì¡í•©ë‹ˆë‹¤"
            )
        elif diff < -5:
            insights.append(
                f"ğŸ“… ì£¼ë§ì´ í‰ì¼ë³´ë‹¤ í‰ê·  **{abs(diff):.1f}%** ë” í˜¼ì¡í•©ë‹ˆë‹¤"
            )
        else:
            insights.append(
                f"ğŸ“… í‰ì¼ê³¼ ì£¼ë§ì˜ í˜¼ì¡ë„ ì°¨ì´ê°€ í¬ì§€ ì•ŠìŠµë‹ˆë‹¤"
            )
    
    # 4. ë°©í–¥ë³„ ë¹„êµ
    direction_avg = station_df.groupby('ë°©í–¥')['í˜¼ì¡ë„'].mean()
    if len(direction_avg) >= 2:
        directions = direction_avg.sort_values()
        less_congested = directions.index[0]
        more_congested = directions.index[-1]
        diff = directions.iloc[-1] - directions.iloc[0]
        
        if diff > 5:
            insights.append(
                f"ğŸš‡ **{less_congested}** ë°©í–¥ì´ **{more_congested}** ë°©í–¥ë³´ë‹¤ í‰ê·  **{diff:.1f}%** ëœ í˜¼ì¡í•©ë‹ˆë‹¤"
            )
    
    # 5. í˜¼ì¡ë„ ë ˆë²¨ ìš”ì•½
    avg_congestion = stats['í‰ê· _í˜¼ì¡ë„']
    if avg_congestion < 50:
        insights.append(
            f"âœ… ì´ ì—­ì€ ì „ë°˜ì ìœ¼ë¡œ **ì—¬ìœ ë¡œìš´** í¸ì…ë‹ˆë‹¤ (í‰ê·  {avg_congestion:.1f}%)"
        )
    elif avg_congestion < 70:
        insights.append(
            f"âš ï¸ ì´ ì—­ì€ **ë³´í†µ** ìˆ˜ì¤€ì˜ í˜¼ì¡ë„ë¥¼ ë³´ì…ë‹ˆë‹¤ (í‰ê·  {avg_congestion:.1f}%)"
        )
    else:
        insights.append(
            f"ğŸ”´ ì´ ì—­ì€ ì „ë°˜ì ìœ¼ë¡œ **í˜¼ì¡í•œ** í¸ì…ë‹ˆë‹¤ (í‰ê·  {avg_congestion:.1f}%)"
        )
    
    return insights


# ============================================================
# Phase 4: ì‹œê°„ëŒ€ë³„ ë¶„ì„ í•¨ìˆ˜
# ============================================================

def get_congestion_by_specific_time(
    df: pd.DataFrame, 
    time_slot: str,
    day_type: str = "ì „ì²´"
) -> pd.DataFrame:
    """
    íŠ¹ì • ì‹œê°„ëŒ€ì˜ ì—­ë³„ í˜¼ì¡ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        time_slot: ì‹œê°„ëŒ€ (ì˜ˆ: "08:00")
        day_type: ìš”ì¼ êµ¬ë¶„ ("í‰ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼", "ì „ì²´")
        
    Returns:
        pd.DataFrame: ì—­ë³„ í˜¼ì¡ë„ (ì—­ëª…, í˜¸ì„ , í˜¼ì¡ë„)
    """
    # ì‹œê°„ëŒ€ í•„í„°ë§
    df_filtered = df[df['ì‹œê°„ëŒ€'] == time_slot].copy()
    
    # ìš”ì¼ í•„í„°ë§
    if day_type != "ì „ì²´":
        if day_type == "íœ´ì¼":
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'].isin(['í† ìš”ì¼', 'ì¼ìš”ì¼'])]
        else:
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'] == day_type]
    
    if df_filtered.empty:
        return pd.DataFrame()
    
    # ì—­ë³„ í‰ê·  í˜¼ì¡ë„ ê³„ì‚° (ë°©í–¥ í‰ê· )
    result = df_filtered.groupby(['ì—­ëª…', 'í˜¸ì„ ', 'í˜¸ì„ _ë²ˆí˜¸']).agg({
        'í˜¼ì¡ë„': 'mean'
    }).reset_index()
    
    result.columns = ['ì—­ëª…', 'í˜¸ì„ ', 'í˜¸ì„ _ë²ˆí˜¸', 'í˜¼ì¡ë„']
    result = result.sort_values('í˜¼ì¡ë„', ascending=False)
    
    return result.reset_index(drop=True)


def get_top_stations_by_time(
    df: pd.DataFrame,
    time_slot: str,
    n: int = 20,
    ascending: bool = False,
    day_type: str = "ì „ì²´"
) -> pd.DataFrame:
    """
    íŠ¹ì • ì‹œê°„ëŒ€ì˜ í˜¼ì¡í•œ ì—­ TOP Nì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        time_slot: ì‹œê°„ëŒ€
        n: ë°˜í™˜í•  ì—­ ê°œìˆ˜
        ascending: Trueë©´ ì—¬ìœ ë¡œìš´ ì—­, Falseë©´ í˜¼ì¡í•œ ì—­
        day_type: ìš”ì¼ êµ¬ë¶„
        
    Returns:
        pd.DataFrame: TOP N ì—­
    """
    time_df = get_congestion_by_specific_time(df, time_slot, day_type)
    
    if time_df.empty:
        return pd.DataFrame()
    
    # ì •ë ¬ ë° TOP N
    result = time_df.sort_values('í˜¼ì¡ë„', ascending=ascending).head(n)
    
    # ìˆœìœ„ ì¶”ê°€
    result = result.reset_index(drop=True)
    result.insert(0, 'ìˆœìœ„', range(1, len(result) + 1))
    
    return result[['ìˆœìœ„', 'ì—­ëª…', 'í˜¸ì„ ', 'í˜¼ì¡ë„']]


def compare_time_slots(
    df: pd.DataFrame,
    time_slot1: str,
    time_slot2: str,
    day_type: str = "ì „ì²´",
    top_n: int = 20
) -> pd.DataFrame:
    """
    ë‘ ì‹œê°„ëŒ€ì˜ í˜¼ì¡ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        time_slot1: ì²« ë²ˆì§¸ ì‹œê°„ëŒ€
        time_slot2: ë‘ ë²ˆì§¸ ì‹œê°„ëŒ€
        day_type: ìš”ì¼ êµ¬ë¶„
        top_n: ìƒìœ„ Nê°œ ì—­ ë¹„êµ
        
    Returns:
        pd.DataFrame: ì‹œê°„ëŒ€ë³„ ë¹„êµ ë°ì´í„°
    """
    # ê° ì‹œê°„ëŒ€ë³„ ë°ì´í„°
    df1 = get_congestion_by_specific_time(df, time_slot1, day_type)
    df2 = get_congestion_by_specific_time(df, time_slot2, day_type)
    
    if df1.empty or df2.empty:
        return pd.DataFrame()
    
    # ë³‘í•©
    df1 = df1.rename(columns={'í˜¼ì¡ë„': f'{time_slot1}_í˜¼ì¡ë„'})
    df2 = df2.rename(columns={'í˜¼ì¡ë„': f'{time_slot2}_í˜¼ì¡ë„'})
    
    merged = pd.merge(
        df1[['ì—­ëª…', 'í˜¸ì„ ', f'{time_slot1}_í˜¼ì¡ë„']],
        df2[['ì—­ëª…', 'í˜¸ì„ ', f'{time_slot2}_í˜¼ì¡ë„']],
        on=['ì—­ëª…', 'í˜¸ì„ '],
        how='inner'
    )
    
    # ì°¨ì´ ê³„ì‚°
    merged['ì°¨ì´'] = merged[f'{time_slot2}_í˜¼ì¡ë„'] - merged[f'{time_slot1}_í˜¼ì¡ë„']
    
    # í‰ê·  í˜¼ì¡ë„ë¡œ ì •ë ¬
    merged['í‰ê· '] = (merged[f'{time_slot1}_í˜¼ì¡ë„'] + merged[f'{time_slot2}_í˜¼ì¡ë„']) / 2
    merged = merged.sort_values('í‰ê· ', ascending=False).head(top_n)
    
    return merged.reset_index(drop=True)


def get_peak_hours_pattern(df: pd.DataFrame, day_type: str = "í‰ì¼") -> Dict:
    """
    ì¶œí‡´ê·¼ ì‹œê°„ëŒ€ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        day_type: ìš”ì¼ êµ¬ë¶„
        
    Returns:
        Dict: í”¼í¬ ì‹œê°„ëŒ€ ì •ë³´
    """
    # ìš”ì¼ í•„í„°ë§
    if day_type != "ì „ì²´":
        if day_type == "íœ´ì¼":
            df_filtered = df[df['ìš”ì¼êµ¬ë¶„'].isin(['í† ìš”ì¼', 'ì¼ìš”ì¼'])]
        else:
            df_filtered = df[df['ìš”ì¼êµ¬ë¶„'] == day_type]
    else:
        df_filtered = df
    
    # ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„
    time_avg = df_filtered.groupby(['ì‹œê°„ëŒ€', 'ì‹œê°„_ì •ë ¬ìš©'])['í˜¼ì¡ë„'].mean().reset_index()
    time_avg = time_avg.sort_values('ì‹œê°„_ì •ë ¬ìš©')
    
    # ì˜¤ì „ í”¼í¬ (7:00-9:00)
    morning_peak = time_avg[
        (time_avg['ì‹œê°„_ì •ë ¬ìš©'] >= 7*60) & 
        (time_avg['ì‹œê°„_ì •ë ¬ìš©'] <= 9*60)
    ]
    
    # ì˜¤í›„ í”¼í¬ (17:00-19:00)
    evening_peak = time_avg[
        (time_avg['ì‹œê°„_ì •ë ¬ìš©'] >= 17*60) & 
        (time_avg['ì‹œê°„_ì •ë ¬ìš©'] <= 19*60)
    ]
    
    result = {}
    
    if not morning_peak.empty:
        max_morning = morning_peak.loc[morning_peak['í˜¼ì¡ë„'].idxmax()]
        result['ì˜¤ì „_í”¼í¬_ì‹œê°„'] = max_morning['ì‹œê°„ëŒ€']
        result['ì˜¤ì „_í”¼í¬_í˜¼ì¡ë„'] = max_morning['í˜¼ì¡ë„']
        result['ì˜¤ì „_í‰ê· _í˜¼ì¡ë„'] = morning_peak['í˜¼ì¡ë„'].mean()
    
    if not evening_peak.empty:
        max_evening = evening_peak.loc[evening_peak['í˜¼ì¡ë„'].idxmax()]
        result['ì˜¤í›„_í”¼í¬_ì‹œê°„'] = max_evening['ì‹œê°„ëŒ€']
        result['ì˜¤í›„_í”¼í¬_í˜¼ì¡ë„'] = max_evening['í˜¼ì¡ë„']
        result['ì˜¤í›„_í‰ê· _í˜¼ì¡ë„'] = evening_peak['í˜¼ì¡ë„'].mean()
    
    return result


def get_time_range_congestion(
    df: pd.DataFrame,
    start_time: str,
    end_time: str,
    day_type: str = "ì „ì²´"
) -> pd.DataFrame:
    """
    ì‹œê°„ ë²”ìœ„ì˜ í‰ê·  í˜¼ì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        start_time: ì‹œì‘ ì‹œê°„ (ì˜ˆ: "07:00")
        end_time: ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: "09:00")
        day_type: ìš”ì¼ êµ¬ë¶„
        
    Returns:
        pd.DataFrame: ì‹œê°„ ë²”ìœ„ì˜ ì—­ë³„ í‰ê·  í˜¼ì¡ë„
    """
    # ì‹œê°„ ë³€í™˜
    start_minutes = int(start_time.split(':')[0]) * 60 + int(start_time.split(':')[1])
    end_minutes = int(end_time.split(':')[0]) * 60 + int(end_time.split(':')[1])
    
    # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
    df_filtered = df[
        (df['ì‹œê°„_ì •ë ¬ìš©'] >= start_minutes) & 
        (df['ì‹œê°„_ì •ë ¬ìš©'] <= end_minutes)
    ].copy()
    
    # ìš”ì¼ í•„í„°ë§
    if day_type != "ì „ì²´":
        if day_type == "íœ´ì¼":
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'].isin(['í† ìš”ì¼', 'ì¼ìš”ì¼'])]
        else:
            df_filtered = df_filtered[df_filtered['ìš”ì¼êµ¬ë¶„'] == day_type]
    
    if df_filtered.empty:
        return pd.DataFrame()
    
    # ì—­ë³„ í‰ê· 
    result = df_filtered.groupby(['ì—­ëª…', 'í˜¸ì„ ', 'í˜¸ì„ _ë²ˆí˜¸']).agg({
        'í˜¼ì¡ë„': 'mean'
    }).reset_index()
    
    result.columns = ['ì—­ëª…', 'í˜¸ì„ ', 'í˜¸ì„ _ë²ˆí˜¸', 'í‰ê· _í˜¼ì¡ë„']
    result = result.sort_values('í‰ê· _í˜¼ì¡ë„', ascending=False)
    
    return result.reset_index(drop=True)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    from data_loader import load_raw_data, save_processed_data
    
    print("=" * 60)
    print("ë°ì´í„° ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    df_raw = load_raw_data()
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    df_processed = preprocess_data(df_raw)
    
    # ìœ íš¨ì„± ê²€ì¦
    is_valid = validate_data(df_processed)
    
    if is_valid:
        # í†µê³„ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ë°ì´í„° í†µê³„")
        print("=" * 60)
        stats = get_statistics(df_processed)
        for key, value in stats.items():
            print(f"{key}: {value}")
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        print("\n" + "=" * 60)
        print("ìƒ˜í”Œ ë°ì´í„° (ì²« 10í–‰)")
        print("=" * 60)
        print(df_processed.head(10))
        
        # ì €ì¥
        print("\n" + "=" * 60)
        save_processed_data(df_processed)
    else:
        print("\nâŒ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨")

